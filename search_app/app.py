"""
Paper Searcher - åŒ»å­¦è«–æ–‡ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã‚¢ãƒ—ãƒª

ChromaDBã«ç™»éŒ²ã•ã‚ŒãŸè«–æ–‡ã‚’ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã§æ¤œç´¢ãƒ»è¡¨ç¤ºã—ã¾ã™ã€‚
"""

import sys
from pathlib import Path
import streamlit as st

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.services.chromadb_service import chromadb_service
from app.config import config
from app.utils.logger import get_logger

logger = get_logger(__name__)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Paper Searcher",
    page_icon="ğŸ”",
    layout="wide",  # PCã§ã¯åºƒãè¡¨ç¤º
    initial_sidebar_state="collapsed"
)

# ã‚«ã‚¹ã‚¿ãƒ CSSï¼ˆãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–å¯¾å¿œï¼‰
st.markdown("""
<style>
    /* åŸºæœ¬ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼ˆPCï¼‰ */
    .main-header {
        text-align: center;
        padding: 1rem 0 2rem 0;
    }
    .search-box {
        max-width: 900px;
        margin: 0 auto 3rem auto;
        padding: 0 1rem;
    }
    .result-card {
        background-color: #f8f9fa;
        border-left: 4px solid #007bff;
        padding: 1.5rem;
        margin-bottom: 1.5rem;
        border-radius: 0.25rem;
    }
    .result-title {
        font-size: 1.3rem;
        font-weight: 600;
        color: #1a1a1a;
        margin-bottom: 0.5rem;
        line-height: 1.4;
    }
    .result-meta {
        color: #6c757d;
        font-size: 0.9rem;
        margin-bottom: 0.75rem;
        line-height: 1.5;
    }
    .result-summary {
        color: #495057;
        line-height: 1.6;
        margin-bottom: 0.75rem;
    }
    .result-links {
        margin-top: 0.75rem;
    }
    .similarity-badge {
        display: inline-block;
        background-color: #28a745;
        color: white;
        padding: 0.25rem 0.75rem;
        border-radius: 1rem;
        font-size: 0.85rem;
        font-weight: 500;
        margin-right: 0.5rem;
    }

    /* ã‚¿ãƒ–ãƒ¬ãƒƒãƒˆå¯¾å¿œ */
    @media (max-width: 1024px) {
        .main .block-container {
            max-width: 100% !important;
            padding-left: 2rem !important;
            padding-right: 2rem !important;
        }
        .search-box {
            max-width: 700px;
        }
    }

    /* ãƒ¢ãƒã‚¤ãƒ«å¯¾å¿œï¼ˆã‚¹ãƒãƒ›ï¼‰ */
    @media (max-width: 768px) {
        .main .block-container {
            max-width: 100% !important;
            padding-left: 1rem !important;
            padding-right: 1rem !important;
        }
        .main-header {
            padding: 0.5rem 0 1rem 0;
        }
        .main-header h1 {
            font-size: 1.8rem !important;
        }
        .main-header p {
            font-size: 0.9rem !important;
        }
        .search-box {
            max-width: 100%;
            padding: 0 0.5rem;
            margin-bottom: 1.5rem;
        }
        .result-card {
            padding: 1rem;
            margin-bottom: 1rem;
        }
        .result-title {
            font-size: 1.05rem;
            line-height: 1.3;
        }
        .result-meta {
            font-size: 0.8rem;
        }
        .similarity-badge {
            font-size: 0.75rem;
            padding: 0.2rem 0.6rem;
        }
        /* ã‚¿ãƒƒãƒæ“ä½œã«é©ã—ãŸãƒœã‚¿ãƒ³ã‚µã‚¤ã‚º */
        .stButton button {
            min-height: 3rem !important;
            font-size: 1rem !important;
        }
    }
</style>
""", unsafe_allow_html=True)


def format_authors(authors_str: str, max_display: int = 3) -> str:
    """
    è‘—è€…ãƒªã‚¹ãƒˆã‚’æ•´å½¢ã—ã¦è¡¨ç¤º

    Args:
        authors_str: ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®è‘—è€…ãƒªã‚¹ãƒˆ
        max_display: æœ€å¤§è¡¨ç¤ºäººæ•°

    Returns:
        æ•´å½¢ã•ã‚ŒãŸè‘—è€…ãƒªã‚¹ãƒˆ
    """
    if not authors_str:
        return "è‘—è€…ä¸æ˜"

    authors = [a.strip() for a in authors_str.split(",")]
    if len(authors) <= max_display:
        return ", ".join(authors)
    else:
        return f"{', '.join(authors[:max_display])}, et al."


def display_search_result(result: dict, index: int):
    """
    æ¤œç´¢çµæœã‚’è¡¨ç¤º

    Args:
        result: æ¤œç´¢çµæœãƒ‡ã‚£ã‚¯ã‚·ãƒ§ãƒŠãƒª
        index: çµæœã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    """
    metadata = result["metadata"]
    similarity = result["similarity"]

    # é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ã®è‰²åˆ†ã‘
    if similarity >= 0.8:
        badge_color = "#28a745"  # ç·‘
    elif similarity >= 0.6:
        badge_color = "#ffc107"  # é»„
    else:
        badge_color = "#6c757d"  # ã‚°ãƒ¬ãƒ¼

    # å¼•ç”¨æ•°ãƒãƒƒã‚¸ã‚’æº–å‚™ï¼ˆç©ºã®å ´åˆã¯HTMLã‚³ãƒ¡ãƒ³ãƒˆã§åŸ‹ã‚ã‚‹ï¼‰
    citations = metadata.get('cited_by_count', '0')
    citation_badge = '<!-- no citations -->'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯HTMLã‚³ãƒ¡ãƒ³ãƒˆ
    try:
        if citations and citations != '0' and int(citations) > 0:
            citation_badge = f'<span class="similarity-badge" style="background-color: #17a2b8; margin-left: 0.5rem;">ğŸ“Š å¼•ç”¨æ•°: {citations}ä»¶</span>'
    except (ValueError, TypeError):
        pass  # å¼•ç”¨æ•°ãŒæ•°å€¤ã«å¤‰æ›ã§ããªã„å ´åˆã¯HTMLã‚³ãƒ¡ãƒ³ãƒˆã®ã¾ã¾

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ã‚’æº–å‚™
    authors_text = format_authors(metadata.get('authors', ''))
    journal = metadata.get('journal', '')
    year = metadata.get('year', '')

    meta_parts = [f"<strong>{authors_text}</strong>"]
    if journal:
        meta_parts.append(journal)
    if year:
        meta_parts.append(f"({year})")

    meta_text = ' | '.join(meta_parts)

    # ã‚«ãƒ¼ãƒ‰è¡¨ç¤º
    st.markdown(f"""
    <div class="result-card">
        <div class="result-title">
            {index}. {metadata.get('title', '(ã‚¿ã‚¤ãƒˆãƒ«ãªã—)')}
        </div>
        <div class="result-meta">
            {meta_text}
        </div>
        <div style="margin-bottom: 0.75rem;">
            <span class="similarity-badge" style="background-color: {badge_color};">
                é–¢é€£åº¦: {similarity:.1%}
            </span>
            {citation_badge}
        </div>
    </div>
    """, unsafe_allow_html=True)

    # è¦ç´„ã‚’å±•é–‹å¯èƒ½ã«
    with st.expander("ğŸ“„ è¦ç´„ã‚’è¡¨ç¤º"):
        # documentãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰è¦ç´„å…¨æ–‡ã‚’å–å¾—
        # documentã¯ã€Œã‚¿ã‚¤ãƒˆãƒ«\n\nè¦ç´„ã€ã®å½¢å¼ãªã®ã§ã€è¦ç´„éƒ¨åˆ†ã‚’æŠ½å‡º
        document = result.get('document', '')
        if document and '\n\n' in document:
            # ã‚¿ã‚¤ãƒˆãƒ«éƒ¨åˆ†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦è¦ç´„ã®ã¿å–å¾—
            summary = document.split('\n\n', 1)[1].strip()
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: metadataã®summaryã‚’ä½¿ç”¨
            summary = metadata.get('summary', '').strip()

        if summary:
            st.write(summary)
        else:
            st.info("è¦ç´„ãŒã‚ã‚Šã¾ã›ã‚“")

    # ãƒªãƒ³ã‚¯è¡¨ç¤ºï¼ˆãƒ¢ãƒã‚¤ãƒ«ã§è¦‹ã‚„ã™ãï¼‰
    links = []
    if metadata.get('notion_url'):
        links.append(f"[ğŸ“ Notion]({metadata['notion_url']})")
    if metadata.get('doi'):
        links.append(f"[ğŸ“„ DOI]({metadata['doi']})")
    if metadata.get('pmid'):
        pmid = metadata['pmid']
        links.append(f"[ğŸ”¬ PubMed](https://pubmed.ncbi.nlm.nih.gov/{pmid}/)")

    if links:
        st.markdown("**ğŸ”— ãƒªãƒ³ã‚¯:** " + " Â· ".join(links))
    else:
        st.caption("ğŸ”— ãƒªãƒ³ã‚¯ãªã—")

    # é–¢é€£è«–æ–‡ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.markdown("")
    st.markdown("**ğŸ”— é–¢é€£è«–æ–‡**")

    # è«–æ–‡IDã‚’å–å¾—
    paper_id = result.get('id')
    if not paper_id:
        st.caption("é–¢é€£è«–æ–‡ã‚’å–å¾—ã§ãã¾ã›ã‚“")
    else:
        # ChromaDBã‹ã‚‰é¡ä¼¼è«–æ–‡ã‚’å–å¾—ï¼ˆ5ä»¶ã«çµã‚‹ï¼‰
        similar_papers = chromadb_service.get_similar_papers(paper_id, n_results=5)

        if not similar_papers:
            st.caption("é–¢é€£è«–æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        else:
            # å„é–¢é€£è«–æ–‡ã‚’ãƒˆã‚°ãƒ«å½¢å¼ã§è¡¨ç¤º
            for i, sim_paper in enumerate(similar_papers, 1):
                sim_metadata = sim_paper["metadata"]
                similarity_score = sim_paper.get("similarity_score", 0)

                # é¡ä¼¼åº¦ã«å¿œã˜ãŸè‰²åˆ†ã‘
                if similarity_score >= 0.8:
                    score_color = "ğŸŸ¢"
                elif similarity_score >= 0.6:
                    score_color = "ğŸŸ¡"
                else:
                    score_color = "ğŸŸ "

                # ã‚¿ã‚¤ãƒˆãƒ«
                title = sim_metadata.get('title', '(ã‚¿ã‚¤ãƒˆãƒ«ãªã—)')

                # ãƒˆã‚°ãƒ«ï¼ˆexpanderï¼‰ã§å„è«–æ–‡ã‚’è¡¨ç¤º
                with st.expander(f"{score_color} {i}. {title[:60]}{'...' if len(title) > 60 else ''} ({similarity_score:.1%})"):
                    # ã‚¿ã‚¤ãƒˆãƒ«å…¨æ–‡
                    st.markdown(f"**{title}**")
                    st.caption(f"é¡ä¼¼åº¦: {similarity_score:.1%}")
                    st.markdown("")

                    # è‘—è€…ãƒ»é›‘èªŒãƒ»å¹´
                    info_parts = []
                    authors = sim_metadata.get('authors', '')
                    if authors:
                        info_parts.append(f"ğŸ‘¥ {format_authors(authors, max_display=5)}")
                    journal = sim_metadata.get('journal', '')
                    year = sim_metadata.get('year', '')
                    if journal:
                        info_parts.append(f"ğŸ“š {journal}")
                    if year:
                        info_parts.append(f"ğŸ“… {year}")
                    citations = sim_metadata.get('cited_by_count', '0')
                    try:
                        if citations and citations != '0' and int(citations) > 0:
                            info_parts.append(f"ğŸ“Š {citations}ä»¶")
                    except (ValueError, TypeError):
                        pass  # å¼•ç”¨æ•°ãŒæ•°å€¤ã«å¤‰æ›ã§ããªã„å ´åˆã¯ä½•ã‚‚è¡¨ç¤ºã—ãªã„

                    if info_parts:
                        st.caption(" | ".join(info_parts))

                    st.markdown("---")

                    # è¦ç´„
                    st.markdown("**ğŸ“ è¦ç´„**")
                    document = sim_paper.get('document', '')
                    if document and '\n\n' in document:
                        summary = document.split('\n\n', 1)[1].strip()
                    else:
                        summary = sim_metadata.get('summary', '').strip()

                    if summary:
                        # è¦ç´„ãŒé•·ã„å ´åˆã¯æœ€åˆã®500æ–‡å­—ã®ã¿è¡¨ç¤º
                        if len(summary) > 500:
                            st.markdown(summary[:500] + "...")
                            st.caption("ï¼ˆè¦ç´„ã®ä¸€éƒ¨ã‚’è¡¨ç¤ºï¼‰")
                        else:
                            st.markdown(summary)
                    else:
                        st.info("è¦ç´„ãŒã‚ã‚Šã¾ã›ã‚“")

                    st.markdown("---")

                    # ãƒªãƒ³ã‚¯ãƒœã‚¿ãƒ³
                    st.markdown("**ğŸ”— ãƒªãƒ³ã‚¯**")
                    btn_col1, btn_col2, btn_col3 = st.columns(3)

                    with btn_col1:
                        notion_url = sim_metadata.get('notion_url')
                        if notion_url:
                            st.link_button(
                                "ğŸ“ Notion",
                                notion_url,
                                use_container_width=True,
                                type="primary"
                            )

                    with btn_col2:
                        doi = sim_metadata.get('doi')
                        if doi:
                            st.link_button("ğŸ“„ DOI", doi, use_container_width=True)

                    with btn_col3:
                        pmid = sim_metadata.get('pmid')
                        if pmid:
                            st.link_button(
                                "ğŸ”¬ PubMed",
                                f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/",
                                use_container_width=True
                            )

    st.markdown("---")


@st.dialog("ğŸ“„ è«–æ–‡è©³ç´°", width="large")
def show_paper_dialog(paper):
    """è«–æ–‡è©³ç´°ã‚’ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã§è¡¨ç¤º"""
    metadata = paper["metadata"]

    # ã‚¿ã‚¤ãƒˆãƒ«
    st.markdown(f"## {metadata.get('title', '(ã‚¿ã‚¤ãƒˆãƒ«ãªã—)')}")

    # ãƒ¡ã‚¿æƒ…å ±
    col1, col2, col3 = st.columns([2, 2, 1])

    with col1:
        authors = metadata.get('authors', '')
        if authors:
            st.markdown(f"**ğŸ‘¥ è‘—è€…**")
            st.caption(format_authors(authors, max_display=10))

    with col2:
        journal = metadata.get('journal', '')
        year = metadata.get('year', '')
        if journal or year:
            st.markdown(f"**ğŸ“š æ²è¼‰èªŒ**")
            journal_year = []
            if journal:
                journal_year.append(journal)
            if year:
                journal_year.append(f"({year})")
            st.caption(' '.join(journal_year))

    with col3:
        citations = metadata.get('cited_by_count', '0')
        try:
            if citations and citations != '0' and int(citations) > 0:
                st.metric("ğŸ“Š è¢«å¼•ç”¨æ•°", f"{citations}ä»¶")
        except (ValueError, TypeError):
            pass  # å¼•ç”¨æ•°ãŒæ•°å€¤ã«å¤‰æ›ã§ããªã„å ´åˆã¯ä½•ã‚‚è¡¨ç¤ºã—ãªã„

    st.markdown("---")

    # è¦ç´„
    st.markdown("### ğŸ“ è¦ç´„")
    document = paper.get('document', '')
    if document and '\n\n' in document:
        summary = document.split('\n\n', 1)[1].strip()
    else:
        summary = metadata.get('summary', '').strip()

    if summary:
        st.markdown(summary)
    else:
        st.info("è¦ç´„ãŒã‚ã‚Šã¾ã›ã‚“")

    st.markdown("---")

    # ãƒªãƒ³ã‚¯ãƒœã‚¿ãƒ³ï¼ˆ3åˆ—ï¼‰
    st.markdown("### ğŸ”— ãƒªãƒ³ã‚¯")
    btn_col1, btn_col2, btn_col3 = st.columns(3)

    with btn_col1:
        notion_url = metadata.get('notion_url')
        if notion_url:
            st.link_button("ğŸ“ Notionã§é–‹ã", notion_url, use_container_width=True, type="primary")
        else:
            st.button("ğŸ“ Notionã§é–‹ã", disabled=True, use_container_width=True)

    with btn_col2:
        doi = metadata.get('doi')
        if doi:
            st.link_button("ğŸ“„ DOI", doi, use_container_width=True)
        else:
            st.button("ğŸ“„ DOI", disabled=True, use_container_width=True)

    with btn_col3:
        pmid = metadata.get('pmid')
        if pmid:
            st.link_button("ğŸ”¬ PubMed", f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/", use_container_width=True)
        else:
            st.button("ğŸ”¬ PubMed", disabled=True, use_container_width=True)

    # é–¢é€£è«–æ–‡ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.markdown("---")
    st.markdown("### ğŸ”— é–¢é€£è«–æ–‡")
    st.caption("ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒƒãƒ—ã§è¿‘ã„ä½ç½®ã®è«–æ–‡ï¼ˆãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ã§é¡ä¼¼ï¼‰")

    # è«–æ–‡IDã‚’å–å¾—
    paper_id = paper.get('id')
    if not paper_id:
        st.warning("è«–æ–‡IDãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    else:
        # ChromaDBã‹ã‚‰é¡ä¼¼è«–æ–‡ã‚’å–å¾—ï¼ˆ10ä»¶ï¼‰
        with st.spinner("é–¢é€£è«–æ–‡ã‚’æ¤œç´¢ä¸­..."):
            similar_papers = chromadb_service.get_similar_papers(paper_id, n_results=10)

        if not similar_papers:
            st.info("é–¢é€£è«–æ–‡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        else:
            st.caption(f"**{len(similar_papers)}ä»¶ã®é–¢é€£è«–æ–‡**")
            st.markdown("")

            # å„é–¢é€£è«–æ–‡ã‚’ãƒˆã‚°ãƒ«å½¢å¼ã§è¡¨ç¤º
            for i, sim_paper in enumerate(similar_papers, 1):
                sim_metadata = sim_paper["metadata"]
                similarity_score = sim_paper.get("similarity_score", 0)

                # é¡ä¼¼åº¦ã«å¿œã˜ãŸè‰²åˆ†ã‘
                if similarity_score >= 0.8:
                    score_color = "ğŸŸ¢"
                elif similarity_score >= 0.6:
                    score_color = "ğŸŸ¡"
                else:
                    score_color = "ğŸŸ "

                # ã‚¿ã‚¤ãƒˆãƒ«
                title = sim_metadata.get('title', '(ã‚¿ã‚¤ãƒˆãƒ«ãªã—)')

                # ãƒˆã‚°ãƒ«ï¼ˆexpanderï¼‰ã§å„è«–æ–‡ã‚’è¡¨ç¤º
                with st.expander(f"{score_color} **{i}. {title}** (é¡ä¼¼åº¦: {similarity_score:.1%})"):
                    # ãƒ¡ã‚¿æƒ…å ±ï¼ˆ3åˆ—ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼‰
                    col1, col2, col3 = st.columns([2, 2, 1])

                    with col1:
                        authors = sim_metadata.get('authors', '')
                        if authors:
                            st.markdown(f"**ğŸ‘¥ è‘—è€…**")
                            st.caption(format_authors(authors, max_display=10))

                    with col2:
                        journal = sim_metadata.get('journal', '')
                        year = sim_metadata.get('year', '')
                        if journal or year:
                            st.markdown(f"**ğŸ“š æ²è¼‰èªŒ**")
                            journal_year = []
                            if journal:
                                journal_year.append(journal)
                            if year:
                                journal_year.append(f"({year})")
                            st.caption(' '.join(journal_year))

                    with col3:
                        citations = sim_metadata.get('cited_by_count', '0')
                        try:
                            if citations and citations != '0' and int(citations) > 0:
                                st.metric("ğŸ“Š è¢«å¼•ç”¨æ•°", f"{citations}ä»¶")
                        except (ValueError, TypeError):
                            pass  # å¼•ç”¨æ•°ãŒæ•°å€¤ã«å¤‰æ›ã§ããªã„å ´åˆã¯ä½•ã‚‚è¡¨ç¤ºã—ãªã„

                    st.markdown("---")

                    # è¦ç´„
                    st.markdown("**ğŸ“ è¦ç´„**")
                    document = sim_paper.get('document', '')
                    if document and '\n\n' in document:
                        summary = document.split('\n\n', 1)[1].strip()
                    else:
                        summary = sim_metadata.get('summary', '').strip()

                    if summary:
                        st.markdown(summary)
                    else:
                        st.info("è¦ç´„ãŒã‚ã‚Šã¾ã›ã‚“")

                    st.markdown("---")

                    # ãƒªãƒ³ã‚¯ãƒœã‚¿ãƒ³ï¼ˆ3åˆ—ï¼‰
                    st.markdown("**ğŸ”— ãƒªãƒ³ã‚¯**")
                    btn_col1, btn_col2, btn_col3 = st.columns(3)

                    with btn_col1:
                        notion_url = sim_metadata.get('notion_url')
                        if notion_url:
                            st.link_button(
                                f"ğŸ“ Notionã§é–‹ã",
                                notion_url,
                                use_container_width=True,
                                type="primary"
                            )
                        else:
                            st.button("ğŸ“ Notionã§é–‹ã", disabled=True, use_container_width=True)

                    with btn_col2:
                        doi = sim_metadata.get('doi')
                        if doi:
                            st.link_button("ğŸ“„ DOI", doi, use_container_width=True)
                        else:
                            st.button("ğŸ“„ DOI", disabled=True, use_container_width=True)

                    with btn_col3:
                        pmid = sim_metadata.get('pmid')
                        if pmid:
                            st.link_button(
                                "ğŸ”¬ PubMed",
                                f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/",
                                use_container_width=True
                            )
                        else:
                            st.button("ğŸ”¬ PubMed", disabled=True, use_container_width=True)


def render_semantic_map():
    """ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒƒãƒ—ã‚’æç”»"""
    st.markdown("### ğŸ“Š ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒƒãƒ—")
    st.markdown("è«–æ–‡ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å…¨ä½“ã‚’2æ¬¡å…ƒç©ºé–“ã§å¯è¦–åŒ–ã—ã¾ã™ã€‚è¿‘ã„ä½ç½®ã«ã‚ã‚‹è«–æ–‡ã¯æ„å‘³çš„ã«é–¢é€£ã—ã¦ã„ã¾ã™ã€‚")

    # è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³
    col1, col2 = st.columns([1, 1])

    with col1:
        limit = st.selectbox(
            "è¡¨ç¤ºã™ã‚‹è«–æ–‡æ•°",
            options=[50, 100, 200, 500, None],
            format_func=lambda x: f"{x}ä»¶" if x else "å…¨ä»¶",
            index=2,
            help="è«–æ–‡æ•°ãŒå¤šã„ã¨å‡¦ç†æ™‚é–“ãŒé•·ããªã‚Šã¾ã™"
        )

    with col2:
        color_by = st.selectbox(
            "è‰²åˆ†ã‘åŸºæº–",
            options=["citations", "year", "journal"],
            format_func=lambda x: "è¢«å¼•ç”¨æ•°" if x == "citations" else ("å¹´åº¦" if x == "year" else "é›‘èªŒ"),
            index=0
        )

    generate_button = st.button("ğŸ—ºï¸ ãƒãƒƒãƒ—ç”Ÿæˆ", type="primary", use_container_width=True)

    # ãƒãƒƒãƒ—ç”Ÿæˆãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã‚‰æ–°è¦ç”Ÿæˆã—ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
    if generate_button:
        with st.spinner("ğŸ“Š ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒƒãƒ—ã‚’ç”Ÿæˆä¸­... (æ•°åç§’ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)"):
            try:
                # ãƒãƒƒãƒ—ç”Ÿæˆ
                map_data = chromadb_service.generate_semantic_map(limit=limit)

                if not map_data["papers"]:
                    st.error(f"âŒ ãƒãƒƒãƒ—ç”Ÿæˆå¤±æ•—: {map_data['stats'].get('error', 'Unknown error')}")
                else:
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
                    st.session_state.map_data = map_data
                    st.session_state.map_limit = limit
                    st.session_state.map_color_by = color_by

            except Exception as e:
                st.error(f"ãƒãƒƒãƒ—ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
                logger.error(f"Semantic map error: {e}")

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ãƒãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°è¡¨ç¤º
    if st.session_state.get('map_data'):
        try:
            map_data = st.session_state.map_data
            color_by = st.session_state.get('map_color_by', 'citations')

            # Plotlyã§æ•£å¸ƒå›³ä½œæˆ
            import plotly.graph_objects as go

            papers = map_data["papers"]
            x_coords = map_data["x"]
            y_coords = map_data["y"]

            # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
            fig = go.Figure()

            if color_by == "citations":
                # è¢«å¼•ç”¨æ•°ã®å ´åˆï¼šå¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã§è‰²åˆ†ã‘
                import numpy as np

                hover_texts = []
                colors = []
                citations_list = []

                for paper in papers:
                    metadata = paper["metadata"]
                    title = metadata.get("title", "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜")
                    authors = metadata.get("authors", "è‘—è€…ä¸æ˜")
                    year = metadata.get("year", "N/A")
                    journal = metadata.get("journal", "é›‘èªŒä¸æ˜")
                    citations = metadata.get("cited_by_count", "0")

                    hover_text = f"<b>{title}</b><br>"
                    hover_text += f"è‘—è€…: {authors}<br>"
                    hover_text += f"é›‘èªŒ: {journal}<br>"
                    hover_text += f"å¹´åº¦: {year}<br>"
                    hover_text += f"è¢«å¼•ç”¨æ•°: {citations}ä»¶"
                    hover_texts.append(hover_text)

                    # è¢«å¼•ç”¨æ•°ã¯æ•°å€¤ã«å¤‰æ›
                    try:
                        citations_num = int(citations) if citations and citations != "0" else 0
                    except (ValueError, TypeError):
                        citations_num = 0
                    citations_list.append(citations_num)

                    # å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã«å¤‰æ› (log(x + 1)ã§0ã‚‚æ‰±ãˆã‚‹)
                    log_citations = np.log1p(citations_num)  # log(citations + 1)
                    colors.append(log_citations)

                # çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—
                max_citations = max(citations_list) if citations_list else 0

                fig.add_trace(go.Scatter(
                    x=x_coords,
                    y=y_coords,
                    mode='markers',
                    marker=dict(
                        size=8,
                        color=colors,
                        colorscale='Plasma',  # æš–è‰²ç³»ã®ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ï¼ˆå¼•ç”¨æ•°ãŒå¤šã„ã»ã©æ˜ã‚‹ãï¼‰
                        showscale=True,
                        colorbar=dict(
                            title="è¢«å¼•ç”¨æ•°<br>(å¯¾æ•°)",
                            tickvals=[0, np.log1p(1), np.log1p(10), np.log1p(100), np.log1p(1000)],
                            ticktext=['0', '1', '10', '100', '1000']
                        ),
                        line=dict(width=0.5, color='white'),
                        opacity=0.7
                    ),
                    text=hover_texts,
                    hovertemplate='%{text}<extra></extra>',
                    customdata=[[i] for i in range(len(papers))],  # è«–æ–‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜
                    showlegend=False
                ))

                # ãƒãƒƒãƒ—ã®è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
                st.session_state.map_papers = papers

            elif color_by == "year":
                # å¹´åº¦ã®å ´åˆï¼šé€£ç¶šçš„ãªã‚«ãƒ©ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«
                hover_texts = []
                colors = []

                for paper in papers:
                    metadata = paper["metadata"]
                    title = metadata.get("title", "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜")
                    authors = metadata.get("authors", "è‘—è€…ä¸æ˜")
                    year = metadata.get("year", "N/A")
                    journal = metadata.get("journal", "é›‘èªŒä¸æ˜")

                    hover_text = f"<b>{title}</b><br>"
                    hover_text += f"è‘—è€…: {authors}<br>"
                    hover_text += f"é›‘èªŒ: {journal}<br>"
                    hover_text += f"å¹´åº¦: {year}"
                    hover_texts.append(hover_text)

                    # å¹´åº¦ã¯æ•°å€¤ã«å¤‰æ›
                    try:
                        year_num = int(year) if year != "N/A" else 2000
                    except (ValueError, TypeError):
                        year_num = 2000
                    colors.append(year_num)

                fig.add_trace(go.Scatter(
                    x=x_coords,
                    y=y_coords,
                    mode='markers',
                    marker=dict(
                        size=8,
                        color=colors,
                        colorscale='Viridis',
                        showscale=True,
                        colorbar=dict(title="å¹´åº¦"),
                        line=dict(width=0.5, color='white'),
                        opacity=0.7
                    ),
                    text=hover_texts,
                    hovertemplate='%{text}<extra></extra>',
                    customdata=[[i] for i in range(len(papers))],  # è«–æ–‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜
                    showlegend=False
                ))

                # ãƒãƒƒãƒ—ã®è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
                st.session_state.map_papers = papers

            else:
                # é›‘èªŒã®å ´åˆï¼šé›‘èªŒã”ã¨ã«ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’ä½œæˆã—ã¦å‡¡ä¾‹è¡¨ç¤º
                # é›‘èªŒã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
                journal_groups = {}
                for i, paper in enumerate(papers):
                    metadata = paper["metadata"]
                    journal = metadata.get("journal", "é›‘èªŒä¸æ˜")[:30]

                    if journal not in journal_groups:
                        journal_groups[journal] = {
                            "x": [],
                            "y": [],
                            "hover_texts": [],
                            "indices": []  # è«–æ–‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¿½åŠ 
                        }

                    journal_groups[journal]["x"].append(x_coords[i])
                    journal_groups[journal]["y"].append(y_coords[i])
                    journal_groups[journal]["indices"].append(i)  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜

                    title = metadata.get("title", "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜")
                    authors = metadata.get("authors", "è‘—è€…ä¸æ˜")
                    year = metadata.get("year", "N/A")
                    hover_text = f"<b>{title}</b><br>"
                    hover_text += f"è‘—è€…: {authors}<br>"
                    hover_text += f"é›‘èªŒ: {journal}<br>"
                    hover_text += f"å¹´åº¦: {year}"
                    journal_groups[journal]["hover_texts"].append(hover_text)

                # é›‘èªŒã®æ•°ãŒå¤šã„å ´åˆã¯ä¸Šä½ã®ã¿è¡¨ç¤ºã€æ®‹ã‚Šã¯"ãã®ä»–"ã«ã¾ã¨ã‚ã‚‹
                max_journals = 15  # å‡¡ä¾‹ã«è¡¨ç¤ºã™ã‚‹æœ€å¤§é›‘èªŒæ•°
                if len(journal_groups) > max_journals:
                    # è«–æ–‡æ•°ãŒå¤šã„é›‘èªŒä¸Šä½ã‚’å–å¾—
                    journal_counts = {j: len(data["x"]) for j, data in journal_groups.items()}
                    top_journals = sorted(journal_counts.items(), key=lambda x: x[1], reverse=True)[:max_journals-1]
                    top_journal_names = [j[0] for j in top_journals]

                    # "ãã®ä»–"ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆ
                    other_group = {"x": [], "y": [], "hover_texts": [], "indices": []}
                    for journal, data in journal_groups.items():
                        if journal not in top_journal_names:
                            other_group["x"].extend(data["x"])
                            other_group["y"].extend(data["y"])
                            other_group["hover_texts"].extend(data["hover_texts"])
                            other_group["indices"].extend(data["indices"])

                    # ä¸Šä½é›‘èªŒã®ã¿æ®‹ã—ã¦ã€ãã®ä»–ã‚’è¿½åŠ 
                    filtered_groups = {j: journal_groups[j] for j in top_journal_names}
                    if other_group["x"]:
                        filtered_groups["ãã®ä»–"] = other_group
                    journal_groups = filtered_groups

                # å„é›‘èªŒã”ã¨ã«ãƒˆãƒ¬ãƒ¼ã‚¹è¿½åŠ 
                for journal, data in sorted(journal_groups.items()):
                    fig.add_trace(go.Scatter(
                        x=data["x"],
                        y=data["y"],
                        mode='markers',
                        name=journal,
                        marker=dict(
                            size=8,
                            line=dict(width=0.5, color='white'),
                            opacity=0.7
                        ),
                        text=data["hover_texts"],
                        hovertemplate='%{text}<extra></extra>',
                        customdata=[[idx] for idx in data["indices"]],  # è«–æ–‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿å­˜
                        showlegend=True
                    ))

                # ãƒãƒƒãƒ—ã®è«–æ–‡ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
                st.session_state.map_papers = papers

            fig.update_layout(
                title=f"è«–æ–‡ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒƒãƒ— ({len(papers)}ä»¶)",
                xaxis_title="",
                yaxis_title="",
                hovermode='closest',
                height=700,
                showlegend=False,
                plot_bgcolor='rgba(240, 240, 240, 0.5)',
                xaxis=dict(showgrid=True, zeroline=False, showticklabels=False),
                yaxis=dict(showgrid=True, zeroline=False, showticklabels=False)
            )

            # ã‚¯ãƒªãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆã‚’æœ‰åŠ¹åŒ–
            event = st.plotly_chart(fig, use_container_width=True, on_select="rerun", selection_mode="points", key="semantic_map")

            # ç¾åœ¨ã®é¸æŠçŠ¶æ…‹ã‚’å–å¾—
            current_selection_id = None
            current_paper_index = None
            if event and event.selection and event.selection.points:
                point = event.selection.points[0]
                if 'customdata' in point and point['customdata']:
                    current_paper_index = point['customdata'][0]
                    current_paper = st.session_state.map_papers[current_paper_index]
                    current_selection_id = current_paper.get('id')

            # å‰å›ã®é¸æŠã¨æ¯”è¼ƒ
            last_selection_id = st.session_state.get('last_selection_id', None)

            # æ–°ã—ã„é¸æŠã®å ´åˆã®ã¿å‡¦ç†ï¼ˆåŒã˜è«–æ–‡ã®é€£ç¶šé¸æŠã‚’é˜²æ­¢ï¼‰
            if current_selection_id and current_selection_id != last_selection_id:
                selected_paper = st.session_state.map_papers[current_paper_index]
                st.session_state.selected_paper_for_dialog = selected_paper
                st.session_state.last_selection_id = current_selection_id
                st.rerun()

            # é¸æŠãŒè§£é™¤ã•ã‚ŒãŸå ´åˆï¼ˆä½•ã‚‚ãªã„å ´æ‰€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ãŸå ´åˆï¼‰
            if not current_selection_id and last_selection_id:
                del st.session_state.last_selection_id

            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«é¸æŠã•ã‚ŒãŸè«–æ–‡ãŒã‚ã‚Œã°ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚’é–‹ã
            if 'selected_paper_for_dialog' in st.session_state:
                selected_paper = st.session_state.selected_paper_for_dialog
                del st.session_state.selected_paper_for_dialog
                show_paper_dialog(selected_paper)

            # çµ±è¨ˆæƒ…å ±
            with st.expander("ğŸ“ˆ ãƒãƒƒãƒ—çµ±è¨ˆæƒ…å ±"):
                stats = map_data["stats"]
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric("è«–æ–‡æ•°", f"{stats['total_papers']}ä»¶")

                with col2:
                    st.metric("åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ", f"{stats['embedding_dim']}æ¬¡å…ƒ")

                with col3:
                    st.metric("è¡¨ç¤ºæ¬¡å…ƒ", "2æ¬¡å…ƒ")

                st.markdown(f"**UMAPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:** n_neighbors={stats['umap_params']['n_neighbors']}, min_dist={stats['umap_params']['min_dist']}")

        except Exception as e:
            st.error(f"ãƒãƒƒãƒ—è¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {e}")
            logger.error(f"Semantic map display error: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ” Paper Searcher</h1>
        <p style="color: #6c757d; font-size: 1.1rem;">Notionè«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œç´¢</p>
    </div>
    """, unsafe_allow_html=True)

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–
    if 'search_results' not in st.session_state:
        st.session_state.search_results = None
    if 'last_query' not in st.session_state:
        st.session_state.last_query = ""
    if 'search_stats' not in st.session_state:
        st.session_state.search_stats = None
    if 'hyde_query' not in st.session_state:
        st.session_state.hyde_query = None
    if 'selected_paper' not in st.session_state:
        st.session_state.selected_paper = None
    if 'map_papers' not in st.session_state:
        st.session_state.map_papers = None

    # ChromaDBç™»éŒ²æ•°è¡¨ç¤º
    try:
        db_count = chromadb_service.get_count()
        st.sidebar.success(f"ğŸ“¦ ç™»éŒ²è«–æ–‡æ•°: {db_count:,}ä»¶")
    except Exception as e:
        st.sidebar.error(f"ChromaDBæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"ChromaDB connection error: {e}")
        return

    # ã‚¿ãƒ–UI
    tab1, tab2 = st.tabs(["ğŸ” æ¤œç´¢", "ğŸ“Š ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒƒãƒ—"])

    with tab1:
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®šï¼ˆãƒ¢ãƒã‚¤ãƒ«ã§ã¯ã‚¨ã‚¯ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ã«æ ¼ç´ï¼‰
        with st.sidebar:
            st.markdown("### âš™ï¸ æ¤œç´¢è¨­å®š")

            # æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰é¸æŠ
            search_mode = st.radio(
                "æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰",
                options=["Deep Searchï¼ˆHyDE + Rerankï¼‰", "Fast Searchï¼ˆé€šå¸¸ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼‰"],
                index=0,
                help="Deep Searchã¯ç²¾åº¦é‡è¦–ã€Fast Searchã¯é€Ÿåº¦é‡è¦–"
            )

            n_results = st.slider(
                "è¡¨ç¤ºä»¶æ•°",
                min_value=5,
                max_value=50,
                value=10,
                step=5
            )

            # Deep Searchè©³ç´°è¨­å®š
            if search_mode == "Deep Searchï¼ˆHyDE + Rerankï¼‰":
                st.markdown("#### Deep Searchè¨­å®š")
                broad_retrieval_size = st.slider(
                    "ä¸­é–“æ¤œç´¢ä»¶æ•°",
                    min_value=20,
                    max_value=50,
                    value=30,
                    step=10,
                    help="ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã§å–å¾—ã™ã‚‹å€™è£œæ•°ï¼ˆå¤šã„ã»ã©ç¶²ç¾…çš„ã€é…ã„ï¼‰"
                )
            else:
                broad_retrieval_size = 30  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

        # æ¤œç´¢ãƒœãƒƒã‚¯ã‚¹
        st.markdown('<div class="search-box">', unsafe_allow_html=True)

        query = st.text_input(
            "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            placeholder="ä¾‹: å°å…ALLã®ç¶­æŒç™‚æ³•",
            label_visibility="collapsed",
            key="search_input"
        )

        search_button = st.button("ğŸ” æ¤œç´¢", type="primary", use_container_width=True)

        st.markdown('</div>', unsafe_allow_html=True)

        # æ¤œç´¢å®Ÿè¡Œ
        if search_button and query:
            if search_mode == "Deep Searchï¼ˆHyDE + Rerankï¼‰":
                # Deep Searchï¼ˆHyDE + Rerankingï¼‰
                status_container = st.empty()

                try:
                    # Step 1: HyDE
                    status_container.info("ğŸ¤– Step 1/3: GeminiãŒé–¢é€£ç”¨èªã‚’æ€è€ƒä¸­...")
                    import time
                    time.sleep(0.5)  # UIè¡¨ç¤ºç”¨ã®çŸ­ã„å¾…æ©Ÿ

                    # Step 2: Vector Search
                    status_container.info("ğŸ” Step 2/3: è«–æ–‡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ¤œç´¢ä¸­...")
                    time.sleep(0.5)

                    # Step 3: Reranking
                    status_container.info("ğŸ¯ Step 3/3: GeminiãŒè«–æ–‡ã‚’ç²¾æŸ»ä¸­...")

                    # Deep Searchå®Ÿè¡Œ
                    search_result = chromadb_service.deep_search(
                        query,
                        n_results=n_results,
                        broad_retrieval_size=broad_retrieval_size
                    )

                    status_container.success("âœ… Deep Searchå®Œäº†!")
                    time.sleep(1)
                    status_container.empty()

                    # çµæœã‚’ä¿å­˜
                    st.session_state.search_results = search_result["results"]
                    st.session_state.last_query = query
                    st.session_state.search_stats = search_result["stats"]
                    st.session_state.hyde_query = search_result["hyde_query"]

                except Exception as e:
                    status_container.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
                    logger.error(f"Deep search error: {e}")
                    return

            else:
                # Fast Searchï¼ˆé€šå¸¸ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼‰
                with st.spinner("ğŸ” æ¤œç´¢ä¸­..."):
                    try:
                        results = chromadb_service.search(query, n_results=n_results)
                        st.session_state.search_results = results
                        st.session_state.last_query = query
                        st.session_state.search_stats = None
                        st.session_state.hyde_query = None
                    except Exception as e:
                        st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
                        logger.error(f"Search error: {e}")
                        return

        # æ¤œç´¢çµæœè¡¨ç¤º
        if st.session_state.search_results is not None:
            results = st.session_state.search_results

            if not results:
                st.info("ğŸ” æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚åˆ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§è©¦ã—ã¦ãã ã•ã„ã€‚")
            else:
                # çµæœãƒ˜ãƒƒãƒ€ãƒ¼
                st.markdown(f"""
                <div style="margin: 2rem 0 1.5rem 0;">
                    <h3>æ¤œç´¢çµæœ: <code>{st.session_state.last_query}</code></h3>
                    <p style="color: #6c757d;">è¦‹ã¤ã‹ã£ãŸè«–æ–‡: {len(results)}ä»¶</p>
                </div>
                """, unsafe_allow_html=True)

                # Deep Searchçµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
                if hasattr(st.session_state, 'search_stats') and st.session_state.search_stats:
                    stats = st.session_state.search_stats
                    with st.expander("ğŸ“Š Deep Searchçµ±è¨ˆæƒ…å ±", expanded=False):
                        col1, col2, col3 = st.columns(3)

                        with col1:
                            st.metric("å€™è£œå–å¾—æ•°", f"{stats.get('broad_retrieval_count', 0)}ä»¶")

                        with col2:
                            st.metric("æœ€çµ‚é¸å‡ºæ•°", f"{stats.get('final_count', 0)}ä»¶")

                        with col3:
                            rerank_ratio = (
                                stats.get('final_count', 0) / stats.get('broad_retrieval_count', 1) * 100
                                if stats.get('broad_retrieval_count', 0) > 0 else 0
                            )
                            st.metric("é¸å‡ºç‡", f"{rerank_ratio:.1f}%")

                        # HyDEã‚¯ã‚¨ãƒªã‚’è¡¨ç¤º
                        if hasattr(st.session_state, 'hyde_query') and st.session_state.hyde_query:
                            st.markdown("**ğŸ¤– ç”Ÿæˆã•ã‚ŒãŸæ¤œç´¢ã‚¯ã‚¨ãƒªï¼ˆHyDEï¼‰:**")
                            st.text_area(
                                "HyDE Query",
                                value=st.session_state.hyde_query,
                                height=150,
                                label_visibility="collapsed"
                            )

                # å„çµæœã‚’è¡¨ç¤º
                for idx, result in enumerate(results, 1):
                    display_search_result(result, idx)

    with tab2:
        # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒƒãƒ—ã‚¿ãƒ–
        render_semantic_map()

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§é¸æŠã•ã‚ŒãŸè«–æ–‡ã®è©³ç´°ã‚’è¡¨ç¤º
    if st.session_state.selected_paper:
        with st.sidebar:
            st.markdown("### ğŸ“„ é¸æŠã•ã‚ŒãŸè«–æ–‡")

            paper = st.session_state.selected_paper
            metadata = paper["metadata"]

            # ã‚¿ã‚¤ãƒˆãƒ«
            st.markdown(f"**{metadata.get('title', '(ã‚¿ã‚¤ãƒˆãƒ«ãªã—)')}**")

            # è‘—è€…
            authors = metadata.get('authors', '')
            if authors:
                st.caption(f"ğŸ‘¥ {format_authors(authors, max_display=5)}")

            # é›‘èªŒãƒ»å¹´åº¦
            journal = metadata.get('journal', '')
            year = metadata.get('year', '')
            if journal or year:
                journal_year = []
                if journal:
                    journal_year.append(journal)
                if year:
                    journal_year.append(f"({year})")
                st.caption(f"ğŸ“š {' '.join(journal_year)}")

            # è¢«å¼•ç”¨æ•°
            citations = metadata.get('cited_by_count', '0')
            try:
                if citations and citations != '0' and int(citations) > 0:
                    st.metric("ğŸ“Š è¢«å¼•ç”¨æ•°", f"{citations}ä»¶")
            except (ValueError, TypeError):
                pass  # å¼•ç”¨æ•°ãŒæ•°å€¤ã«å¤‰æ›ã§ããªã„å ´åˆã¯ä½•ã‚‚è¡¨ç¤ºã—ãªã„

            st.markdown("---")

            # è¦ç´„ã‚’è¡¨ç¤º
            st.markdown("**ğŸ“ è¦ç´„**")
            # documentãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰è¦ç´„å…¨æ–‡ã‚’å–å¾—
            document = paper.get('document', '')
            if document and '\n\n' in document:
                # ã‚¿ã‚¤ãƒˆãƒ«éƒ¨åˆ†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦è¦ç´„ã®ã¿å–å¾—
                summary = document.split('\n\n', 1)[1].strip()
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: metadataã®summaryã‚’ä½¿ç”¨
                summary = metadata.get('summary', '').strip()

            if summary:
                # é•·ã„è¦ç´„ã¯æœ€åˆã®500æ–‡å­—ã®ã¿è¡¨ç¤º
                if len(summary) > 500:
                    st.text_area("", summary[:500] + "...", height=200, label_visibility="collapsed")
                    with st.expander("å…¨æ–‡ã‚’è¡¨ç¤º"):
                        st.write(summary)
                else:
                    st.text_area("", summary, height=200, label_visibility="collapsed")
            else:
                st.info("è¦ç´„ãŒã‚ã‚Šã¾ã›ã‚“")

            st.markdown("---")

            # ãƒªãƒ³ã‚¯ãƒœã‚¿ãƒ³
            st.markdown("**ğŸ”— ãƒªãƒ³ã‚¯**")

            notion_url = metadata.get('notion_url')
            if notion_url:
                st.link_button("ğŸ“ Notionã§é–‹ã", notion_url, use_container_width=True, type="primary")

            doi = metadata.get('doi')
            if doi:
                st.link_button("ğŸ“„ DOI", doi, use_container_width=True)

            pmid = metadata.get('pmid')
            if pmid:
                st.link_button("ğŸ”¬ PubMed", f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/", use_container_width=True)

            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            keywords = metadata.get('keywords', '')
            if keywords:
                st.markdown("---")
                st.markdown("**ğŸ·ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**")
                keyword_list = [k.strip() for k in keywords.split(',') if k.strip()]
                # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒãƒƒã‚¸ã¨ã—ã¦è¡¨ç¤º
                keyword_html = ' '.join([f'<span style="background-color: #e9ecef; padding: 0.25rem 0.5rem; border-radius: 0.25rem; font-size: 0.8rem; margin-right: 0.25rem; display: inline-block; margin-bottom: 0.25rem;">{kw}</span>' for kw in keyword_list[:10]])
                st.markdown(keyword_html, unsafe_allow_html=True)

            # é–‰ã˜ã‚‹ãƒœã‚¿ãƒ³
            st.markdown("---")
            if st.button("âœ• é–‰ã˜ã‚‹", use_container_width=True):
                st.session_state.selected_paper = None
                st.rerun()

    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #6c757d; padding: 0.5rem 0;">
        <p style="font-size: 0.85rem; margin: 0;">Paper Searcher v1.8</p>
        <p style="font-size: 0.75rem; margin: 0.25rem 0 0 0;">Gemini Embedding + gemma-3-27b-it + ChromaDB</p>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"Application error: {e}")
